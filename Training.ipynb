{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECTROGRAM_TRAIN_TFRECORD_FILENAME = \"spectrogram_train.tfrecord\"\n",
    "SPECTROGRAM_VALID_TFRECORD_FILENAME = \"spectrogram_valid.tfrecord\"\n",
    "DATA_DIR = \"data\"\n",
    "BUFFER_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "SPECTROGRAM_SHAPE = (85, 129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 11 10:40:04 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 106...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 32%   32C    P8     6W / 120W |      0MiB /  6078MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset([os.path.join(DATA_DIR, SPECTROGRAM_TRAIN_TFRECORD_FILENAME)])\n",
    "valid_dataset = tf.data.TFRecordDataset([os.path.join(DATA_DIR, SPECTROGRAM_VALID_TFRECORD_FILENAME)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'spectrogram': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    'label': tf.io.FixedLenFeature([], tf.float32, default_value=0.0)\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    spectrogram = tf.io.parse_tensor(example['spectrogram'], out_type=tf.float32)\n",
    "    spectrogram = tf.ensure_shape(spectrogram, SPECTROGRAM_SHAPE)\n",
    "    label = tf.ensure_shape(example['label'], ())\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function _parse_function at 0x7fe0242951f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _parse_function at 0x7fe0242951f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(_parse_function)\n",
    "valid_dataset = valid_dataset.map(_parse_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(85, 129), dtype=float32, numpy=\n",
      "array([[3.79017234e-01, 1.37462819e+00, 3.20527291e+00, ...,\n",
      "        2.03023610e-05, 4.91823666e-05, 1.59546733e-04],\n",
      "       [1.34324759e-01, 1.31664729e+00, 3.49691677e+00, ...,\n",
      "        1.01808109e-04, 1.20156576e-04, 9.34302807e-05],\n",
      "       [7.57609010e-02, 1.05255270e+00, 2.61501384e+00, ...,\n",
      "        7.29629246e-05, 3.64155385e-05, 2.37822533e-05],\n",
      "       ...,\n",
      "       [3.68746817e-01, 1.46235037e+00, 3.51829767e+00, ...,\n",
      "        4.68326034e-05, 5.54631079e-05, 7.57128000e-05],\n",
      "       [6.25966415e-02, 9.80049014e-01, 2.85418606e+00, ...,\n",
      "        8.71873126e-05, 1.01852413e-04, 8.16807151e-05],\n",
      "       [3.01045269e-01, 1.19051707e+00, 2.84571457e+00, ...,\n",
      "        4.19902790e-05, 1.61160388e-05, 2.91764736e-05]], dtype=float32)>, <tf.Tensor: shape=(), dtype=float32, numpy=0.0>)\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(BUFFER_SIZE).cache()\n",
    "valid_dataset = valid_dataset.batch(BATCH_SIZE).prefetch(BUFFER_SIZE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model parameters copied from tutorial: https://www.tensorflow.org/tutorials/audio/simple_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 85, 129, 1)        0         \n",
      "_________________________________________________________________\n",
      "resizing (Resizing)          (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 32, 32, 129)       259       \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        37184     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1605760   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 1,661,957\n",
      "Trainable params: 1,661,698\n",
      "Non-trainable params: 259\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "norm_layer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
    "norm_layer.adapt(train_dataset.map(lambda x, _: x))\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=SPECTROGRAM_SHAPE),\n",
    "    tf.keras.layers.Reshape((SPECTROGRAM_SHAPE[0], SPECTROGRAM_SHAPE[1], 1)),\n",
    "    tf.keras.layers.experimental.preprocessing.Resizing(32, 32),\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "163/163 [==============================] - 24s 86ms/step - loss: 628.5253 - accuracy: 0.7500 - val_loss: 0.6008 - val_accuracy: 0.7776\n",
      "Epoch 2/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.5650 - accuracy: 0.7822 - val_loss: 0.4313 - val_accuracy: 0.7779\n",
      "Epoch 3/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.5268 - accuracy: 0.7822 - val_loss: 0.3786 - val_accuracy: 0.7776\n",
      "Epoch 4/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.4737 - accuracy: 0.7826 - val_loss: 0.3549 - val_accuracy: 0.7776\n",
      "Epoch 5/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.4413 - accuracy: 0.7826 - val_loss: 0.3200 - val_accuracy: 0.7776\n",
      "Epoch 6/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.3952 - accuracy: 0.7825 - val_loss: 0.2875 - val_accuracy: 0.7776\n",
      "Epoch 7/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.3760 - accuracy: 0.7826 - val_loss: 0.2606 - val_accuracy: 0.7776\n",
      "Epoch 8/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.3462 - accuracy: 0.7826 - val_loss: 0.2524 - val_accuracy: 0.7776\n",
      "Epoch 9/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.3407 - accuracy: 0.7815 - val_loss: 0.2472 - val_accuracy: 0.7776\n",
      "Epoch 10/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.3373 - accuracy: 0.7826 - val_loss: 0.2367 - val_accuracy: 0.7776\n",
      "Epoch 11/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.3213 - accuracy: 0.8014 - val_loss: 0.2261 - val_accuracy: 0.9541\n",
      "Epoch 12/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.3178 - accuracy: 0.8393 - val_loss: 0.2699 - val_accuracy: 0.9359\n",
      "Epoch 13/20\n",
      "163/163 [==============================] - 2s 12ms/step - loss: 0.3708 - accuracy: 0.8235 - val_loss: 0.3288 - val_accuracy: 0.8323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fdf640cf6d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(train_dataset, epochs=20, validation_data=valid_dataset, callbacks=tf.keras.callbacks.EarlyStopping(patience=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
